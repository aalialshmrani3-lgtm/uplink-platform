"""
Success Prediction Microservice for UPLINK 5.0
Uses XGBoost for idea success prediction
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import logging
import numpy as np
from sklearn.ensemble import RandomForestClassifier
import joblib
import os

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="UPLINK Success Prediction API",
    description="ML-based idea success prediction",
    version="1.0.0"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global model (loaded once at startup)
prediction_model = None
MODEL_PATH = "/tmp/success_prediction_model.pkl"

@app.on_event("startup")
async def load_model():
    """Load or create the prediction model on startup"""
    global prediction_model
    try:
        if os.path.exists(MODEL_PATH):
            logger.info(f"Loading existing model from {MODEL_PATH}...")
            prediction_model = joblib.load(MODEL_PATH)
            logger.info("âœ… Model loaded successfully")
        else:
            logger.info("No existing model found, creating mock model...")
            # Create a simple mock model for demonstration
            # In production, this would be trained on real data
            prediction_model = RandomForestClassifier(n_estimators=100, random_state=42)
            # Mock training data (features: title_length, description_length, budget, sector_encoded)
            X_mock = np.random.rand(100, 4)
            y_mock = np.random.choice([0, 1], 100)  # 0=fail, 1=success
            prediction_model.fit(X_mock, y_mock)
            joblib.dump(prediction_model, MODEL_PATH)
            logger.info("âœ… Mock model created and saved")
    except Exception as e:
        logger.error(f"âŒ Failed to load/create model: {e}")
        raise

# Request/Response models
class IdeaInput(BaseModel):
    title: str
    description: str
    keywords: Optional[List[str]] = []
    sector: str
    budget: float
    team_size: Optional[int] = 1

class SuccessPredictionResponse(BaseModel):
    success_probability: float
    risk_level: str  # High, Medium, Low
    confidence: float
    key_factors: List[Dict[str, Any]]
    recommendations: List[str]

class IdeaInsightsResponse(BaseModel):
    idea_id: int
    success_probability: float
    risk_level: str
    key_success_factors: List[Dict[str, Any]]
    similar_successful_ideas: List[Dict[str, Any]]
    recommendations: List[str]

# Helper functions
def extract_features(idea: IdeaInput) -> np.ndarray:
    """Extract features from idea input"""
    # Simple feature extraction for demonstration
    features = [
        len(idea.title),  # Title length
        len(idea.description),  # Description length
        idea.budget,  # Budget
        hash(idea.sector) % 10,  # Sector encoded (mock)
    ]
    return np.array(features).reshape(1, -1)

def calculate_risk_level(probability: float) -> str:
    """Calculate risk level based on success probability"""
    if probability >= 0.7:
        return "Low"
    elif probability >= 0.4:
        return "Medium"
    else:
        return "High"

def generate_recommendations(probability: float, idea: IdeaInput) -> List[str]:
    """Generate recommendations based on prediction"""
    recommendations = []
    
    if probability < 0.4:
        recommendations.append("âš ï¸ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ù†Ø¬Ø§Ø­ Ù…Ù†Ø®ÙØ¶Ø© - ÙŠÙÙ†ØµØ­ Ø¨Ø¥Ø¹Ø§Ø¯Ø© ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙÙƒØ±Ø©")
        recommendations.append("ðŸ’¡ Ù‚Ù… Ø¨ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØµÙ ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„")
        recommendations.append("ðŸ‘¥ ÙÙƒØ± ÙÙŠ ØªÙˆØ³ÙŠØ¹ Ø§Ù„ÙØ±ÙŠÙ‚ Ø£Ùˆ Ø¥Ø¶Ø§ÙØ© Ø®Ø¨Ø±Ø§Øª Ù…ØªÙ†ÙˆØ¹Ø©")
    elif probability < 0.7:
        recommendations.append("âœ… Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù†Ø¬Ø§Ø­ Ù…ØªÙˆØ³Ø·Ø© - Ù‡Ù†Ø§Ùƒ Ø¥Ù…ÙƒØ§Ù†Ø§Øª Ø¬ÙŠØ¯Ø©")
        recommendations.append("ðŸ“Š Ù‚Ù… Ø¨Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø£Ø¨Ø­Ø§Ø« Ø§Ù„Ø³ÙˆÙ‚")
        recommendations.append("ðŸŽ¯ Ø­Ø¯Ø¯ Ø£Ù‡Ø¯Ø§ÙØ§Ù‹ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù‚ÙŠØ§Ø³")
    else:
        recommendations.append("ðŸŽ‰ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ù†Ø¬Ø§Ø­ Ø¹Ø§Ù„ÙŠØ© - ÙÙƒØ±Ø© ÙˆØ§Ø¹Ø¯Ø©!")
        recommendations.append("ðŸš€ Ø§Ø¨Ø¯Ø£ Ø¨Ø§Ù„ØªØ®Ø·ÙŠØ· Ù„Ù„ØªÙ†ÙÙŠØ°")
        recommendations.append("ðŸ“ˆ Ø­Ø¯Ø¯ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (KPIs)")
    
    # Budget-based recommendations
    if idea.budget < 10000:
        recommendations.append("ðŸ’° Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ù…Ø­Ø¯ÙˆØ¯Ø© - Ø±ÙƒØ² Ø¹Ù„Ù‰ MVP (Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù…Ù† Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚)")
    
    return recommendations

@app.get("/")
async def root():
    """Health check endpoint"""
    return {
        "service": "UPLINK Success Prediction",
        "status": "running",
        "model": "RandomForest (Mock)"
    }

@app.post("/predict", response_model=SuccessPredictionResponse)
async def predict_success(idea: IdeaInput):
    """
    Predict success probability for a new idea
    
    Args:
        idea: IdeaInput containing idea details
        
    Returns:
        SuccessPredictionResponse with prediction and recommendations
    """
    try:
        # Extract features
        features = extract_features(idea)
        
        # Predict
        probability = prediction_model.predict_proba(features)[0][1]  # Probability of success
        
        # Calculate risk level
        risk_level = calculate_risk_level(probability)
        
        # Generate key factors (mock - in production, use SHAP values)
        key_factors = [
            {"factor": "Ø§Ù„ÙˆØµÙ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ", "impact": "Ø¹Ø§Ù„ÙŠ", "score": 0.85},
            {"factor": "Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©", "impact": "Ù…ØªÙˆØ³Ø·", "score": 0.65},
            {"factor": "Ø§Ù„Ù‚Ø·Ø§Ø¹ Ø§Ù„ÙˆØ§Ø¹Ø¯", "impact": "Ù…ØªÙˆØ³Ø·", "score": 0.70},
        ]
        
        # Generate recommendations
        recommendations = generate_recommendations(probability, idea)
        
        return SuccessPredictionResponse(
            success_probability=float(probability),
            risk_level=risk_level,
            confidence=0.75,  # Mock confidence
            key_factors=key_factors,
            recommendations=recommendations
        )
    except Exception as e:
        logger.error(f"Error predicting success: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/insights/{idea_id}", response_model=IdeaInsightsResponse)
async def get_idea_insights(idea_id: int):
    """
    Get comprehensive insights for an existing idea
    
    Args:
        idea_id: ID of the idea
        
    Returns:
        IdeaInsightsResponse with detailed insights
    """
    try:
        # In production, fetch idea from database
        # For now, return mock data
        
        # Mock similar successful ideas
        similar_ideas = [
            {
                "id": 123,
                "title": "Ù…Ù†ØµØ© ØªØ¹Ù„ÙŠÙ…ÙŠØ© ØªÙØ§Ø¹Ù„ÙŠØ©",
                "success_rate": 0.92,
                "sector": "Ø§Ù„ØªØ¹Ù„ÙŠÙ…"
            },
            {
                "id": 456,
                "title": "ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹",
                "success_rate": 0.88,
                "sector": "Ø§Ù„ØªÙ‚Ù†ÙŠØ©"
            }
        ]
        
        return IdeaInsightsResponse(
            idea_id=idea_id,
            success_probability=0.78,
            risk_level="Low",
            key_success_factors=[
                {"factor": "ÙØ±ÙŠÙ‚ Ù…ØªÙ…Ø±Ø³", "importance": 0.9},
                {"factor": "Ø³ÙˆÙ‚ ÙˆØ§Ø¶Ø­", "importance": 0.85},
                {"factor": "Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙƒØ§ÙÙŠØ©", "importance": 0.75}
            ],
            similar_successful_ideas=similar_ideas,
            recommendations=[
                "ðŸŽ¯ Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø¨Ù†Ø§Ø¡ MVP Ø³Ø±ÙŠØ¹",
                "ðŸ‘¥ Ø§Ø³ØªÙ‚Ø·Ø¨ Ø®Ø¨Ø±Ø§Ø¡ ÙÙŠ Ø§Ù„Ù…Ø¬Ø§Ù„",
                "ðŸ“Š Ø§Ø¨Ø¯Ø£ Ø¨Ù‚ÙŠØ§Ø³ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ù…Ø¨ÙƒØ±Ø§Ù‹"
            ]
        )
    except Exception as e:
        logger.error(f"Error getting idea insights: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/retrain")
async def retrain_model(training_data: Optional[Dict] = None):
    """
    Retrain the model with new data
    
    Args:
        training_data: Optional training data
        
    Returns:
        Status of retraining
    """
    try:
        # In production, this would retrain with real data from database
        logger.info("Retraining model with new data...")
        
        # Mock retraining
        global prediction_model
        X_new = np.random.rand(50, 4)
        y_new = np.random.choice([0, 1], 50)
        prediction_model.fit(X_new, y_new)
        
        # Save updated model
        joblib.dump(prediction_model, MODEL_PATH)
        
        logger.info("âœ… Model retrained successfully")
        return {
            "status": "success",
            "message": "Model retrained and saved",
            "timestamp": "2026-01-29T15:00:00Z"
        }
    except Exception as e:
        logger.error(f"Error retraining model: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)
